# ML100Days
機器學習百日馬拉松作業

1. 機器學習概論

[D1:資料介紹與評估資料](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_001_HW.ipynb)

[D2:機器學習概論](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_002_HW.ipynb)

[D3:機器學習-流程與步驟](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_003_HW.ipynb)

[D4:EDA/讀取資料與分析流程](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_004_HW.ipynb)

2. 資料清理數據前處理

[D5：如何新建一個 dataframe? 如何讀取其他資料? (非 csv 的資料)](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_005_HW.ipynb)

[D6：EDA：欄位的資料類型介紹及處理](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_006_HW.ipynb)

[D7：特徵類型](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_007_HW.ipynb)

[D8：EDA資料分佈](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_008_HW.ipynb)

[D9：EDA：Outlier 及處理](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_009_HW.ipynb)

[D10：數值型特徵 - 去除離群值](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_010_HW.ipynb)

[D11：常用的數值取代：中位數與分位數連續數值標準化](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_011_HW.ipynb)

[D12：數值型特徵 - 補缺失值與標準化](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_012_HW.ipynb)

[D13：DataFrame operationData frame merge/常用的 DataFrame 操作](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_013_HW.ipynb)

[D14：程式實作 EDA: correlation/相關係數簡介](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_014_HW.ipynb)

[D15：EDA from Correlation](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_015_HW.ipynb)

[D16：EDA: 不同數值範圍間的特徵如何檢視/繪圖與樣式Kernel Density Estimation (KDE)](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_016_HW.ipynb)

[D17：EDA: 把連續型變數離散化](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_017_HW.ipynb)

[D18：程式實作 把連續型變數離散化](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_018_HW.ipynb)

[D19：Subplots](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_019_HW.ipynb)

[D20：Heatmap & Grid-plot](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_020_HW.ipynb)

[D21：模型初體驗 Logistic Regression](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_021_HW.JPG)

3. 資料科學特徵工程技術

[D22：特徵工程簡介](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_022_HW.ipynb)

[D23：數值型特徵 - 去除偏態](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_023_HW.ipynb)

[D24：類別型特徵 - 基礎處理](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_024_HW.ipynb)

[D25：類別型特徵 - 均值編碼](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_025_HW.ipynb)

[D26：類別型特徵 - 其他進階處理](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_026_HW.ipynb)

[D27：時間型特徵](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_027_HW.ipynb)

[D28：特徵組合 - 數值與數值組合](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_028_HW.ipynb)

[D29：特徵組合 - 類別與數值組合](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_029_HW.ipynb)

[D30：特徵選擇](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_030_HW.ipynb)

[D31：特徵評估](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_031_HW.ipynb)

[D32：分類型特徵優化 - 葉編碼](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_032_HW.ipynb)

4. 機器學習基礎模型建立

[D33：機器如何學習?](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_033_HW.ipynb)

[D34：訓練/測試集切分的概念](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_034_HW.ipynb)

[D35：regression vs. classification](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_035_HW.ipynb)

[D36：評估指標選定/evaluation metrics](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_036_HW.ipynb)

[D37：regression model 介紹 - 線性迴歸/羅吉斯回歸](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_037_HW.ipynb)

[D38：regression model 程式碼撰寫](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_038_HW.ipynb)

[D39：regression model 介紹 - LASSO 回歸/ Ridge 回歸](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_039_HW.ipynb)

[D40：regression model 程式碼撰寫](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_040_HW.ipynb)

[D41：tree based model - 決策樹 (Decision Tree) 模型介紹](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_041_HW.ipynb)

[D42：tree based model - 決策樹程式碼撰寫](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_042_HW.ipynb)

[D43：tree based model - 隨機森林 (Random Forest) 介紹](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_043_HW.ipynb)

[D44：tree based model - 隨機森林程式碼撰寫](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_044_HW.ipynb)

[D45：tree based model - 梯度提升機 (Gradient Boosting Machine) 介紹](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_045_HW.ipynb)

[D46：tree based model - 梯度提升機程式碼撰寫](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_046_HW.ipynb)

5. 機器學習調整參數

[D47：超參數調整與優化](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_047_HW.JPG)

[D48：Kaggle 競賽平台介紹](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_048_HW.JPG)

[D49：集成方法 : 混合泛化(Blending)](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_049_HW.JPG)

[D50：集成方法 : 堆疊泛化(Stacking)](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_050_HW.JPG)

[D51 - D53：Kaggle期中考 考ML與調參相關](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day051-053_MidTerm.JPG)

6. 非監督式機器學習

[D54：非監督式機器學習簡介](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_054_HW.ipynb)

[D55：非監督式學習—分群算法 / K-Means 分群](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_055_HW.ipynb)

[D56：分群算法 — K-means 分群評估 : 使用輪廓分析](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_056_HW.ipynb)

[D57：分群算法 — 階層式分群 Hierarchical Clustering](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_057_HW.ipynb)

[D58：分群算法 — 階層分群法 觀察 : 使用 2D 樣版資料集](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_058_HW.ipynb)

[D59：dimension reduction 1 降維方法-主成份分析](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_059_HW.ipynb)

[D60：PCA 觀察 : 使用手寫辨識資料集](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_060_HW.ipynb)

[D61：dimension reduction 2 降維方法-T-SNE](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_061_HW.ipynb)

[D62：t-sne 觀察 : 分群與流形還原](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_062_tsne.ipynb)

7. 深度學習理論及實作

[D63：深度學習簡介](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_063_HW.ipynb)

[D64：深度學習體驗 : 模型調整與學習曲線](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_064_HW.ipynb)

[D65：深度學習體驗 : 啟動函數與正規化](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day_065_HW.ipynb)

8. 初探深度學習及Keras

[D66：Keras 安裝與介紹](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day066_HW.ipynb)

[D67：Keras Dataset](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day067_HW.ipynb)

[D68：Keras Sequential API](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day068_HW.ipynb)

[D69：Keras Module API](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day069_HW.ipynb)

[D70：深度神經網路的基礎知識](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day070_HW.ipynb)

[D71：損失函數](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day071_HW.ipynb)

[D72：啟動函數](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day072_HW.ipynb)

[D73：梯度下降Gradient Descent](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day073_HW.ipynb)

[D74：Gradient Descent 數學原理](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day074_HW.ipynb)

[D75：BackPropagation](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day075_HW.ipynb)

[D76：優化器optimizers](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day076_HW.ipynb)

[D77：訓練神經網路的細節與技巧 - Validation and overfit](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day077_HW.ipynb)

[D78：訓練神經網路前的注意事項](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day078_HW.ipynb)

[D79：訓練神經網路的細節與技巧 - Learning rate effect](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day079_HW.ipynb)

[D80：[練習 Day] 優化器與學習率的組合與比較](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day080_HW.ipynb)

[D81：訓練神經網路的細節與技巧 - Regularization](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day081_HW.ipynb)

[D82：訓練神經網路的細節與技巧 - Dropout](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day082_HW.ipynb)

[D83：訓練神經網路的細節與技巧 - Batch normalization](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day083_HW.ipynb)

[D84：[練習 Day] 正規化/機移除/批次標準化的 組合與比較](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day084_HW.ipynb)

[D85：訓練神經網路的細節與技巧 - 使用 callbacks 函數做 earlystop](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day085_HW.ipynb)

[D86：訓練神經網路的細節與技巧 - 使用 callbacks 函數儲存 model](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day086_HW.ipynb)

[D87：訓練神經網路的細節與技巧 - 使用 callbacks 函數做 reduce learning rate](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day087_HW.ipynb)

[D88：訓練神經網路的細節與技巧 - 撰寫自己的 callbacks 函數](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day088_HW.ipynb)

[D89：訓練神經網路的細節與技巧 - 撰寫自己的 Loss function](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day089_HW.ipynb)

[D90：使用傳統電腦視覺與機器學習進行影像辨識](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day090_color_histogram_HW.ipynb)

[D91：[練習 Day] 使用傳統電腦視覺與機器學習進行影像辨識](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day091_classification_with_cv_HW.ipynb)

9. 深度學習應用捲積神經網路

[D92：卷積神經網路 (Convolution Neural Network, CNN) 簡介](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day092_CNN_theory.ipynb)

[D93：卷積神經網路架構細節](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day93_CNN_Brief_HW.ipynb)

[D94：卷積神經網路 - 卷積(Convolution)層與參數調整](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day94_CNN_Convolution_HW.ipynb)

[D95：卷積神經網路 - 池化(Pooling)層與參數調整](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day95_CNN_Pooling_Padding_HW.ipynb)

[D96：Keras 中的 CNN layers](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day096_Keras_CNN_layers.ipynb)

[D97：使用 CNN 完成 CIFAR-10 資料集](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day097_Keras_CNN_vs_DNN.ipynb)

[D98：訓練卷積神經網路的細節與技巧 - 處理大量數據](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day098_Python_generator.ipynb)

[D99：訓練卷積神經網路的細節與技巧 - 處理小量數據](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day099_data_augmentation.ipynb)

[D100：訓練卷積神經網路的細節與技巧 - 轉移學習 (Transfer learning)](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day100_transfer_learning_HW.ipynb)

Kaggle期末考(1)

[D101 - D103：影像辨識](https://github.com/ChiHsuChen/ML100Days/blob/master/homework/Day101-103-Final.PNG)

10. Bonus進階補充

D104：史丹佛線上 ConvNetJS 簡介

D105：CNN 卷積網路回顧

D106：電腦視覺常⽤公開資料集

D107：電腦視覺應用介紹
